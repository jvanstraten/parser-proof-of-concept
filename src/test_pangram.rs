// SPDX-License-Identifier: WTFPL

// Note: this file is generated by a very cursed Python script and is itself
// also quite cursed. Pretty much nothing of what's in here is idiomatic.
// Its only point is to provide a positive test case for something that isn't
// just a toy example.
#![allow(non_snake_case)]
#![allow(unused)]
#![allow(clippy::type_complexity)]
#![allow(clippy::vec_box)]

use super::prelude::*;

mod types {

    /// Trait for things that have a span.
    pub trait Spanned {
        type Span;

        fn span(&self) -> &Self::Span;
    }

    //=============================================================================

    /// Trait for the types of tokens within a language.
    pub trait TokenType: Copy + Eq + std::hash::Hash + std::fmt::Debug + std::fmt::Display {
        /// Array-like type returned by all().
        type All: IntoIterator<Item = Self>;

        /// Returns an iterator that iterates over all tokens, in the order in
        /// which they should be matched by the tokenizer.
        fn all() -> Self::All;

        /// Returns the regex for this token type.
        fn regex(&self) -> &'static str;

        /// Returns the regex for matching whitespace between the real tokens.
        fn whitespace() -> &'static str;
    }

    //=============================================================================

    /// Token classification.
    #[derive(Clone, Copy, Debug, PartialEq, Eq, Hash)]
    pub enum TokenClass<T> {
        /// Used for normal tokens, that the parser should consume.
        Normal(T),

        /// Used for the whitespace between normal tokens.
        Whitespace,

        /// Used to recover from errors; matches any single character when nothing
        /// else matches.
        Error,
    }

    impl<T: TokenType> TokenClass<T> {
        /// Returns the embedded token type if there is one.
        fn token_type(&self) -> Option<T> {
            if let Self::Normal(token_type) = self {
                Some(*token_type)
            } else {
                None
            }
        }

        /// Returns whether this is an error token.
        fn is_error(&self) -> bool {
            matches!(self, Self::Error)
        }

        /// Returns whether this is a whitespace token.
        fn is_whitespace(&self) -> bool {
            matches!(self, Self::Whitespace)
        }
    }

    impl<T: TokenType> std::fmt::Display for TokenClass<T> {
        fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
            match self {
                TokenClass::Normal(token_type) => std::fmt::Display::fmt(token_type, f),
                TokenClass::Whitespace => write!(f, "whitespace"),
                TokenClass::Error => write!(f, "error"),
            }
        }
    }

    //=============================================================================

    /// Tokens as emitted by the tokenizer. This includes errors and whitespace
    /// in addition to regular terminals in the grammar.
    #[derive(Clone, Debug, PartialEq, Eq, Hash)]
    pub struct Token<'a, T, L>
    where
        L: crate::location::Tracker<&'a str>,
    {
        class: TokenClass<T>,
        text: &'a str,
        span: L::Span,
    }

    impl<'a, T, L> Token<'a, T, L>
    where
        T: TokenType,
        L: crate::location::Tracker<&'a str>,
    {
        /// Creates a new token.
        pub fn new(class: TokenClass<T>, text: &'a str, span: L::Span) -> Self {
            Self { class, text, span }
        }

        /// Converts self to a [TerminalToken] if it is a normal token. Otherwise
        /// returns Err(self).
        pub fn into_grammar_input(self) -> Result<TerminalToken<T, L::Span>, Self> {
            if let Some(token_type) = self.class.token_type() {
                Ok(TerminalToken::new(token_type, self.text, self.span))
            } else {
                Err(self)
            }
        }

        /// Converts self to a [TokenizerError] if it is an error marker. Otherwise
        /// returns Err(self).
        pub fn into_error(self) -> Result<TokenizerError<L::Span>, Self> {
            if self.class.is_error() {
                Ok(TokenizerError::new(
                    self.text.chars().next().unwrap_or('?'),
                    self.span,
                ))
            } else {
                Err(self)
            }
        }

        /// Returns the class of this token.
        pub fn class(&self) -> TokenClass<T> {
            self.class
        }

        /// Returns the text encompassed by the token.
        pub fn text(&self) -> &'a str {
            self.text
        }
    }

    impl<'a, T, L> std::fmt::Display for Token<'a, T, L>
    where
        T: TokenType,
        L: crate::location::Tracker<&'a str>,
        L::Span: std::fmt::Display,
    {
        fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {
            write!(f, "{} ({:?} at {})", self.class, self.text, self.span)
        }
    }

    impl<'a, T, L> Spanned for Token<'a, T, L>
    where
        L: crate::location::Tracker<&'a str>,
    {
        type Span = L::Span;

        fn span(&self) -> &Self::Span {
            &self.span
        }
    }

    //=============================================================================

    /// Error type used for a failure to tokenize.
    #[derive(Clone, Debug)]
    pub struct TokenizerError<S> {
        invalid_char: char,
        location: S,
    }

    impl<S: std::fmt::Display> std::fmt::Display for TokenizerError<S> {
        fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
            write!(
                f,
                "failed to match character {:?} as the start of a token at {}",
                self.invalid_char, self.location
            )
        }
    }

    impl<S> TokenizerError<S> {
        pub fn new(invalid_char: char, location: S) -> Self {
            Self {
                invalid_char,
                location,
            }
        }
    }

    //=============================================================================

    pub struct Tokenizer<'s, T, L = crate::location::Simple> {
        regexes: Vec<(regex::Regex, TokenClass<T>)>,
        location: L,
        index: usize,
        remain: &'s str,
    }

    impl<'s, T, L> Tokenizer<'s, T, L>
    where
        T: TokenType,
        L: crate::location::Tracker<&'s str>,
    {
        /// Creates a tokenizer for a piece of text with the given initial location
        /// for spans.
        pub fn new_with_location(location: L, text: &'s str) -> Self {
            let mut regexes: Vec<_> = T::all()
                .into_iter()
                .map(|x| {
                    (
                        regex::Regex::new(&format!("^(?:{})", x.regex())).unwrap(),
                        TokenClass::Normal(x),
                    )
                })
                .collect();
            regexes.push((
                regex::Regex::new(&format!("^(?:{})", T::whitespace())).unwrap(),
                TokenClass::Whitespace,
            ));
            Self {
                regexes,
                location,
                index: 0,
                remain: text,
            }
        }

        /// Creates a tokenizer for a piece of text, using L::default() for the
        /// initial location.
        pub fn new(text: &'s str) -> Self
        where
            L: Default,
        {
            Self::new_with_location(L::default(), text)
        }
    }

    impl<'s, T, L> Iterator for Tokenizer<'s, T, L>
    where
        T: TokenType,
        L: crate::location::Tracker<&'s str>,
    {
        type Item = Token<'s, T, L>;

        fn next(&mut self) -> Option<Self::Item> {
            // Stop when we reach EOF.
            if self.remain.is_empty() {
                return None;
            }

            // Look for the first longest match.
            let mut token_type = TokenClass::Error;
            let mut length = 0;
            for (regex, candidate_token_type) in self.regexes.iter() {
                let candidate_length = regex
                    .captures(self.remain)
                    .and_then(|x| x.get(0))
                    .map(|x| x.as_str().len())
                    .unwrap_or_default();
                if candidate_length > length {
                    token_type = *candidate_token_type;
                    length = candidate_length;
                }
            }

            // Advance by at least one character, even if nothing matched, in
            // an attempt to recover from errors.
            if length == 0 {
                length = 1;
            }

            // Generate the token and seek past it.
            let text = &self.remain[..length];
            self.remain = &self.remain[length..];
            let start_location = self.location.clone();
            let start_index = self.index;
            self.location.advance(&text);
            self.index += 1;
            let span = start_location.spanning_to(start_index, &self.location, self.index);
            let token = Token::new(token_type, text, span);

            Some(token)
        }
    }

    //=============================================================================

    /// Token type used as terminals at the input of the grammar. This type is a
    /// bit derpy to make Chumsky work right: two terminal tokens are equal iff
    /// they have the same type, with no bearing on the text or span. The text or
    /// span are treated as optional annotations, used only to aid in the
    /// construction of error messages.
    #[derive(Clone, Debug, Eq)]
    pub struct TerminalToken<T: TokenType, S> {
        token_type: T,
        text: Option<String>,
        span: S,
    }

    impl<T: TokenType, S> PartialEq for TerminalToken<T, S> {
        fn eq(&self, other: &Self) -> bool {
            self.token_type == other.token_type
        }
    }

    impl<T: TokenType, S> std::hash::Hash for TerminalToken<T, S> {
        fn hash<H: std::hash::Hasher>(&self, state: &mut H) {
            self.token_type.hash(state);
        }
    }

    impl<T: TokenType, S> TerminalToken<T, S> {
        /// Creates a new terminal node.
        pub fn new<R: ToString>(token_type: T, text: R, span: S) -> Self {
            Self {
                token_type,
                text: Some(text.to_string()),
                span,
            }
        }

        /// Creates a new "pattern" node, only used for error messages and to
        /// compare against.
        pub fn new_pattern(token_type: T) -> Self
        where
            S: Default,
        {
            Self {
                token_type,
                text: None,
                span: S::default(),
            }
        }

        /// Returns the token type.
        pub fn token_type(&self) -> T {
            self.token_type
        }

        /// Returns the text enclosed by the token.
        pub fn text(&self) -> &str {
            self.text.as_ref().map(|x| &x[..]).unwrap_or("")
        }

        /// Unwraps the contents into a tuple.
        pub fn unwrap(self) -> (T, Option<String>, S) {
            (self.token_type, self.text, self.span)
        }
    }

    impl<T: TokenType, S: std::fmt::Display> std::fmt::Display for TerminalToken<T, S> {
        fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {
            if let Some(text) = &self.text {
                write!(f, "{} ({:?}) at {}", self.token_type, text, self.span)
            } else {
                write!(f, "{}", self.token_type)
            }
        }
    }

    impl<T: TokenType, S> Spanned for TerminalToken<T, S> {
        type Span = S;

        fn span(&self) -> &S {
            &self.span
        }
    }

    //=============================================================================

    // Error type used for both parsing and tokenization.
    #[derive(Clone, Debug)]
    pub enum Error<'i, L>
    where
        L: crate::location::Tracker<&'i str>,
        L::Location: Clone + std::fmt::Debug + std::fmt::Display,
        L::Span: Clone + std::fmt::Debug + std::fmt::Display,
    {
        TokenizerError(TokenizerError<L::Location>),
        ParserError(crate::error::Simple<&'i str, L>),
    }

    impl<'i, L> std::fmt::Display for Error<'i, L>
    where
        L: crate::location::Tracker<&'i str>,
        L::Location: Clone + std::fmt::Debug + std::fmt::Display,
        L::Span: Clone + std::fmt::Debug + std::fmt::Display,
    {
        fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
            match self {
                Error::TokenizerError(e) => write!(f, "{e}"),
                Error::ParserError(e) => write!(f, "{e}"),
            }
        }
    }
}

#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash)]
pub enum TokenType {
    /// Implicit token.
    ColEqEq,

    /// Implicit token.
    Sem,

    /// Implicit token.
    Usc,

    /// All symbol names are written in kebab-case. GrammarSpec will convert the
    /// names to the appropriate case conventions for the target language.
    Symbol,

    /// Implicit token.
    Bar,

    /// Implicit token.
    ColColEq,

    /// Implicit token.
    MinGt,

    /// Implicit token.
    Qst,

    /// Implicit token.
    Ast,

    /// Implicit token.
    Pls,

    /// Implicit token.
    Lp,

    /// Implicit token.
    Rp,

    /// `'...'` and `"..."` match `...` literally. Empty string literals are not
    /// supported; instead use `?`.
    StringLiteral,

    /// `[...]` matches a single character within the specified set. `a-z` may be
    /// used to select a whole range of code points, and a `^` at the front of the
    /// `...` inverts the set.
    CharacterSet,

    /// Hash escape sequences for characters can also be matched outside the context
    /// of a string or character range.
    CharacterLiteral,

    /// /** comments are treated as docstrings. They may only appear immediately in
    /// front of a rule or toplevel alternative in a grammar production rule.
    Doc,
}

impl types::TokenType for TokenType {
    type All = [TokenType; 16];

    fn all() -> Self::All {
        [
            Self::ColEqEq,
            Self::Sem,
            Self::Usc,
            Self::Symbol,
            Self::Bar,
            Self::ColColEq,
            Self::MinGt,
            Self::Qst,
            Self::Ast,
            Self::Pls,
            Self::Lp,
            Self::Rp,
            Self::StringLiteral,
            Self::CharacterSet,
            Self::CharacterLiteral,
            Self::Doc,
        ]
    }

    fn regex(&self) -> &'static str {
        match self {
            Self::ColEqEq => ":==",
            Self::Sem => ";",
            Self::Usc => "_",
            Self::Symbol => "(?:[a-z])(?:(?:[a-z0-9\\-])*)",
            Self::Bar => "\\|",
            Self::ColColEq => "::=",
            Self::MinGt => "\\->",
            Self::Qst => "\\?",
            Self::Ast => "\\*",
            Self::Pls => "\\+",
            Self::Lp => "\\(",
            Self::Rp => "\\)",
            Self::StringLiteral => "(?:(?:')(?:(?:(?:[^'#])|(?:(?:#)(?:.)))+)(?:'))|(?:(?:\")(?:(?:(?:[^\"#])|(?:(?:#)(?:.)))+)(?:\"))",
            Self::CharacterSet => "(?:\\[)(?:(?:\\^)?)(?:(?:(?:(?:(?:[^\\^\\-\\]#])|(?:(?:(?:#)(?:(?:[^xuU])|(?:(?:x)(?:(?:[0-9a-fA-F]))(?:(?:[0-9a-fA-F])))|(?:(?:u)(?:(?:[0-9a-fA-F]))(?:(?:[0-9a-fA-F]))(?:(?:[0-9a-fA-F]))(?:(?:[0-9a-fA-F])))|(?:(?:U)(?:(?:[0-9a-fA-F]))(?:(?:[0-9a-fA-F]))(?:(?:[0-9a-fA-F]))(?:(?:[0-9a-fA-F]))(?:(?:[0-9a-fA-F]))(?:(?:[0-9a-fA-F]))(?:(?:[0-9a-fA-F]))(?:(?:[0-9a-fA-F]))))))))(?:(?:(?:\\-)(?:(?:(?:[^\\^\\-\\]#])|(?:(?:(?:#)(?:(?:[^xuU])|(?:(?:x)(?:(?:[0-9a-fA-F]))(?:(?:[0-9a-fA-F])))|(?:(?:u)(?:(?:[0-9a-fA-F]))(?:(?:[0-9a-fA-F]))(?:(?:[0-9a-fA-F]))(?:(?:[0-9a-fA-F])))|(?:(?:U)(?:(?:[0-9a-fA-F]))(?:(?:[0-9a-fA-F]))(?:(?:[0-9a-fA-F]))(?:(?:[0-9a-fA-F]))(?:(?:[0-9a-fA-F]))(?:(?:[0-9a-fA-F]))(?:(?:[0-9a-fA-F]))(?:(?:[0-9a-fA-F])))))))))?))*)(?:\\])",
            Self::CharacterLiteral => "(?:(?:#)(?:(?:[^xuU])|(?:(?:x)(?:(?:[0-9a-fA-F]))(?:(?:[0-9a-fA-F])))|(?:(?:u)(?:(?:[0-9a-fA-F]))(?:(?:[0-9a-fA-F]))(?:(?:[0-9a-fA-F]))(?:(?:[0-9a-fA-F])))|(?:(?:U)(?:(?:[0-9a-fA-F]))(?:(?:[0-9a-fA-F]))(?:(?:[0-9a-fA-F]))(?:(?:[0-9a-fA-F]))(?:(?:[0-9a-fA-F]))(?:(?:[0-9a-fA-F]))(?:(?:[0-9a-fA-F]))(?:(?:[0-9a-fA-F])))))",
            Self::Doc => "(?:/\\*\\*)(?:(?:(?:(?:(?:[^\\*])|(?:(?:(?:\\*)+)(?:[^\\*/])))*)(?:(?:\\*)*)))(?:\\*/)",
        }
    }

    fn whitespace() -> &'static str {
        "(?:(?:/\\*)(?:(?:(?:[^\\*])(?:(?:(?:(?:(?:[^\\*])|(?:(?:(?:\\*)+)(?:[^\\*/])))*)(?:(?:\\*)*))))?)(?:\\*/))|(?:(?:[ \t\n\r])+)"
    }
}

impl std::fmt::Display for TokenType {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(f, "{:?}", self)
    }
}

/// Tokenizes a piece of text.
pub fn tokenize(text: &str) -> types::Tokenizer<TokenType> {
    types::Tokenizer::new(text)
}

/// Tokenizes a piece of text starting from the given source location.
pub fn tokenize_from<'s, L: crate::location::Tracker<&'s str>>(
    location: L,
    text: &'s str,
) -> types::Tokenizer<'s, TokenType, L> {
    types::Tokenizer::new_with_location(location, text)
}

/// Helper type for a boxed parser.
pub type BoxedParser<'i, T, S> =
    crate::combinator::Boxed<'i, &'i types::TerminalToken<TokenType, S>, T>;

/// Helper type for the contents of a token.
#[derive(Clone, Debug, PartialEq, Eq, Hash)]
pub struct TokenData<'i, S> {
    pub token: &'i types::TerminalToken<TokenType, S>,
    pub index: usize,
}

/// Struct containing patterns for all terminal tokens, to be referenced by the
/// parsers. Must be constructed using Default before the parsers and kept
/// alive throughout their lifetime.
pub struct TerminalPatterns<S> {
    pub ColEqEq: types::TerminalToken<TokenType, S>,
    pub Sem: types::TerminalToken<TokenType, S>,
    pub Usc: types::TerminalToken<TokenType, S>,
    pub Symbol: types::TerminalToken<TokenType, S>,
    pub Bar: types::TerminalToken<TokenType, S>,
    pub ColColEq: types::TerminalToken<TokenType, S>,
    pub MinGt: types::TerminalToken<TokenType, S>,
    pub Qst: types::TerminalToken<TokenType, S>,
    pub Ast: types::TerminalToken<TokenType, S>,
    pub Pls: types::TerminalToken<TokenType, S>,
    pub Lp: types::TerminalToken<TokenType, S>,
    pub Rp: types::TerminalToken<TokenType, S>,
    pub StringLiteral: types::TerminalToken<TokenType, S>,
    pub CharacterSet: types::TerminalToken<TokenType, S>,
    pub CharacterLiteral: types::TerminalToken<TokenType, S>,
    pub Doc: types::TerminalToken<TokenType, S>,
}

impl<S> Default for TerminalPatterns<S>
where
    S: Default,
{
    fn default() -> Self {
        Self {
            ColEqEq: types::TerminalToken::new_pattern(TokenType::ColEqEq),
            Sem: types::TerminalToken::new_pattern(TokenType::Sem),
            Usc: types::TerminalToken::new_pattern(TokenType::Usc),
            Symbol: types::TerminalToken::new_pattern(TokenType::Symbol),
            Bar: types::TerminalToken::new_pattern(TokenType::Bar),
            ColColEq: types::TerminalToken::new_pattern(TokenType::ColColEq),
            MinGt: types::TerminalToken::new_pattern(TokenType::MinGt),
            Qst: types::TerminalToken::new_pattern(TokenType::Qst),
            Ast: types::TerminalToken::new_pattern(TokenType::Ast),
            Pls: types::TerminalToken::new_pattern(TokenType::Pls),
            Lp: types::TerminalToken::new_pattern(TokenType::Lp),
            Rp: types::TerminalToken::new_pattern(TokenType::Rp),
            StringLiteral: types::TerminalToken::new_pattern(TokenType::StringLiteral),
            CharacterSet: types::TerminalToken::new_pattern(TokenType::CharacterSet),
            CharacterLiteral: types::TerminalToken::new_pattern(TokenType::CharacterLiteral),
            Doc: types::TerminalToken::new_pattern(TokenType::Doc),
        }
    }
}

/// Implicit token.
#[derive(Clone, Debug, Default, PartialEq, Eq, Hash)]
pub struct PtColEqEq<'i, S> {
    pub data: Option<TokenData<'i, S>>,
}

impl<'i, S: Default + Eq + std::hash::Hash> PtColEqEq<'i, S> {
    fn new(
        token: &'i types::TerminalToken<TokenType, S>,
        token_span: std::ops::Range<usize>,
    ) -> Self {
        assert!(token.token_type() == TokenType::ColEqEq);
        Self {
            data: Some(TokenData {
                token,
                index: token_span.start,
            }),
        }
    }

    /// Visit this terminal node with the given visitor.
    pub fn visit<E, V: Visitor<'i, S, E>>(&self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_ColEqEq(self)
    }

    /// Visit this terminal node with the given visitor.
    pub fn visit_mut<E, V: VisitorMut<'i, S, E>>(&mut self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_ColEqEq(self)
    }
}

/// Implicit token.
#[derive(Clone, Debug, Default, PartialEq, Eq, Hash)]
pub struct PtSem<'i, S> {
    pub data: Option<TokenData<'i, S>>,
}

impl<'i, S: Default + Eq + std::hash::Hash> PtSem<'i, S> {
    fn new(
        token: &'i types::TerminalToken<TokenType, S>,
        token_span: std::ops::Range<usize>,
    ) -> Self {
        assert!(token.token_type() == TokenType::Sem);
        Self {
            data: Some(TokenData {
                token,
                index: token_span.start,
            }),
        }
    }

    /// Visit this terminal node with the given visitor.
    pub fn visit<E, V: Visitor<'i, S, E>>(&self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_Sem(self)
    }

    /// Visit this terminal node with the given visitor.
    pub fn visit_mut<E, V: VisitorMut<'i, S, E>>(&mut self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_Sem(self)
    }
}

/// Implicit token.
#[derive(Clone, Debug, Default, PartialEq, Eq, Hash)]
pub struct PtUsc<'i, S> {
    pub data: Option<TokenData<'i, S>>,
}

impl<'i, S: Default + Eq + std::hash::Hash> PtUsc<'i, S> {
    fn new(
        token: &'i types::TerminalToken<TokenType, S>,
        token_span: std::ops::Range<usize>,
    ) -> Self {
        assert!(token.token_type() == TokenType::Usc);
        Self {
            data: Some(TokenData {
                token,
                index: token_span.start,
            }),
        }
    }

    /// Visit this terminal node with the given visitor.
    pub fn visit<E, V: Visitor<'i, S, E>>(&self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_Usc(self)
    }

    /// Visit this terminal node with the given visitor.
    pub fn visit_mut<E, V: VisitorMut<'i, S, E>>(&mut self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_Usc(self)
    }
}

/// All symbol names are written in kebab-case. GrammarSpec will convert the
/// names to the appropriate case conventions for the target language.
#[derive(Clone, Debug, Default, PartialEq, Eq, Hash)]
pub struct PtSymbol<'i, S> {
    pub data: Option<TokenData<'i, S>>,
}

impl<'i, S: Default + Eq + std::hash::Hash> PtSymbol<'i, S> {
    fn new(
        token: &'i types::TerminalToken<TokenType, S>,
        token_span: std::ops::Range<usize>,
    ) -> Self {
        assert!(token.token_type() == TokenType::Symbol);
        Self {
            data: Some(TokenData {
                token,
                index: token_span.start,
            }),
        }
    }

    /// Visit this terminal node with the given visitor.
    pub fn visit<E, V: Visitor<'i, S, E>>(&self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_Symbol(self)
    }

    /// Visit this terminal node with the given visitor.
    pub fn visit_mut<E, V: VisitorMut<'i, S, E>>(&mut self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_Symbol(self)
    }
}

/// Implicit token.
#[derive(Clone, Debug, Default, PartialEq, Eq, Hash)]
pub struct PtBar<'i, S> {
    pub data: Option<TokenData<'i, S>>,
}

impl<'i, S: Default + Eq + std::hash::Hash> PtBar<'i, S> {
    fn new(
        token: &'i types::TerminalToken<TokenType, S>,
        token_span: std::ops::Range<usize>,
    ) -> Self {
        assert!(token.token_type() == TokenType::Bar);
        Self {
            data: Some(TokenData {
                token,
                index: token_span.start,
            }),
        }
    }

    /// Visit this terminal node with the given visitor.
    pub fn visit<E, V: Visitor<'i, S, E>>(&self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_Bar(self)
    }

    /// Visit this terminal node with the given visitor.
    pub fn visit_mut<E, V: VisitorMut<'i, S, E>>(&mut self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_Bar(self)
    }
}

/// Implicit token.
#[derive(Clone, Debug, Default, PartialEq, Eq, Hash)]
pub struct PtColColEq<'i, S> {
    pub data: Option<TokenData<'i, S>>,
}

impl<'i, S: Default + Eq + std::hash::Hash> PtColColEq<'i, S> {
    fn new(
        token: &'i types::TerminalToken<TokenType, S>,
        token_span: std::ops::Range<usize>,
    ) -> Self {
        assert!(token.token_type() == TokenType::ColColEq);
        Self {
            data: Some(TokenData {
                token,
                index: token_span.start,
            }),
        }
    }

    /// Visit this terminal node with the given visitor.
    pub fn visit<E, V: Visitor<'i, S, E>>(&self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_ColColEq(self)
    }

    /// Visit this terminal node with the given visitor.
    pub fn visit_mut<E, V: VisitorMut<'i, S, E>>(&mut self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_ColColEq(self)
    }
}

/// Implicit token.
#[derive(Clone, Debug, Default, PartialEq, Eq, Hash)]
pub struct PtMinGt<'i, S> {
    pub data: Option<TokenData<'i, S>>,
}

impl<'i, S: Default + Eq + std::hash::Hash> PtMinGt<'i, S> {
    fn new(
        token: &'i types::TerminalToken<TokenType, S>,
        token_span: std::ops::Range<usize>,
    ) -> Self {
        assert!(token.token_type() == TokenType::MinGt);
        Self {
            data: Some(TokenData {
                token,
                index: token_span.start,
            }),
        }
    }

    /// Visit this terminal node with the given visitor.
    pub fn visit<E, V: Visitor<'i, S, E>>(&self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_MinGt(self)
    }

    /// Visit this terminal node with the given visitor.
    pub fn visit_mut<E, V: VisitorMut<'i, S, E>>(&mut self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_MinGt(self)
    }
}

/// Implicit token.
#[derive(Clone, Debug, Default, PartialEq, Eq, Hash)]
pub struct PtQst<'i, S> {
    pub data: Option<TokenData<'i, S>>,
}

impl<'i, S: Default + Eq + std::hash::Hash> PtQst<'i, S> {
    fn new(
        token: &'i types::TerminalToken<TokenType, S>,
        token_span: std::ops::Range<usize>,
    ) -> Self {
        assert!(token.token_type() == TokenType::Qst);
        Self {
            data: Some(TokenData {
                token,
                index: token_span.start,
            }),
        }
    }

    /// Visit this terminal node with the given visitor.
    pub fn visit<E, V: Visitor<'i, S, E>>(&self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_Qst(self)
    }

    /// Visit this terminal node with the given visitor.
    pub fn visit_mut<E, V: VisitorMut<'i, S, E>>(&mut self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_Qst(self)
    }
}

/// Implicit token.
#[derive(Clone, Debug, Default, PartialEq, Eq, Hash)]
pub struct PtAst<'i, S> {
    pub data: Option<TokenData<'i, S>>,
}

impl<'i, S: Default + Eq + std::hash::Hash> PtAst<'i, S> {
    fn new(
        token: &'i types::TerminalToken<TokenType, S>,
        token_span: std::ops::Range<usize>,
    ) -> Self {
        assert!(token.token_type() == TokenType::Ast);
        Self {
            data: Some(TokenData {
                token,
                index: token_span.start,
            }),
        }
    }

    /// Visit this terminal node with the given visitor.
    pub fn visit<E, V: Visitor<'i, S, E>>(&self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_Ast(self)
    }

    /// Visit this terminal node with the given visitor.
    pub fn visit_mut<E, V: VisitorMut<'i, S, E>>(&mut self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_Ast(self)
    }
}

/// Implicit token.
#[derive(Clone, Debug, Default, PartialEq, Eq, Hash)]
pub struct PtPls<'i, S> {
    pub data: Option<TokenData<'i, S>>,
}

impl<'i, S: Default + Eq + std::hash::Hash> PtPls<'i, S> {
    fn new(
        token: &'i types::TerminalToken<TokenType, S>,
        token_span: std::ops::Range<usize>,
    ) -> Self {
        assert!(token.token_type() == TokenType::Pls);
        Self {
            data: Some(TokenData {
                token,
                index: token_span.start,
            }),
        }
    }

    /// Visit this terminal node with the given visitor.
    pub fn visit<E, V: Visitor<'i, S, E>>(&self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_Pls(self)
    }

    /// Visit this terminal node with the given visitor.
    pub fn visit_mut<E, V: VisitorMut<'i, S, E>>(&mut self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_Pls(self)
    }
}

/// Implicit token.
#[derive(Clone, Debug, Default, PartialEq, Eq, Hash)]
pub struct PtLp<'i, S> {
    pub data: Option<TokenData<'i, S>>,
}

impl<'i, S: Default + Eq + std::hash::Hash> PtLp<'i, S> {
    fn new(
        token: &'i types::TerminalToken<TokenType, S>,
        token_span: std::ops::Range<usize>,
    ) -> Self {
        assert!(token.token_type() == TokenType::Lp);
        Self {
            data: Some(TokenData {
                token,
                index: token_span.start,
            }),
        }
    }

    /// Visit this terminal node with the given visitor.
    pub fn visit<E, V: Visitor<'i, S, E>>(&self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_Lp(self)
    }

    /// Visit this terminal node with the given visitor.
    pub fn visit_mut<E, V: VisitorMut<'i, S, E>>(&mut self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_Lp(self)
    }
}

/// Implicit token.
#[derive(Clone, Debug, Default, PartialEq, Eq, Hash)]
pub struct PtRp<'i, S> {
    pub data: Option<TokenData<'i, S>>,
}

impl<'i, S: Default + Eq + std::hash::Hash> PtRp<'i, S> {
    fn new(
        token: &'i types::TerminalToken<TokenType, S>,
        token_span: std::ops::Range<usize>,
    ) -> Self {
        assert!(token.token_type() == TokenType::Rp);
        Self {
            data: Some(TokenData {
                token,
                index: token_span.start,
            }),
        }
    }

    /// Visit this terminal node with the given visitor.
    pub fn visit<E, V: Visitor<'i, S, E>>(&self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_Rp(self)
    }

    /// Visit this terminal node with the given visitor.
    pub fn visit_mut<E, V: VisitorMut<'i, S, E>>(&mut self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_Rp(self)
    }
}

/// `'...'` and `"..."` match `...` literally. Empty string literals are not
/// supported; instead use `?`.
#[derive(Clone, Debug, Default, PartialEq, Eq, Hash)]
pub struct PtStringLiteral<'i, S> {
    pub data: Option<TokenData<'i, S>>,
}

impl<'i, S: Default + Eq + std::hash::Hash> PtStringLiteral<'i, S> {
    fn new(
        token: &'i types::TerminalToken<TokenType, S>,
        token_span: std::ops::Range<usize>,
    ) -> Self {
        assert!(token.token_type() == TokenType::StringLiteral);
        Self {
            data: Some(TokenData {
                token,
                index: token_span.start,
            }),
        }
    }

    /// Visit this terminal node with the given visitor.
    pub fn visit<E, V: Visitor<'i, S, E>>(&self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_StringLiteral(self)
    }

    /// Visit this terminal node with the given visitor.
    pub fn visit_mut<E, V: VisitorMut<'i, S, E>>(&mut self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_StringLiteral(self)
    }
}

/// `[...]` matches a single character within the specified set. `a-z` may be
/// used to select a whole range of code points, and a `^` at the front of the
/// `...` inverts the set.
#[derive(Clone, Debug, Default, PartialEq, Eq, Hash)]
pub struct PtCharacterSet<'i, S> {
    pub data: Option<TokenData<'i, S>>,
}

impl<'i, S: Default + Eq + std::hash::Hash> PtCharacterSet<'i, S> {
    fn new(
        token: &'i types::TerminalToken<TokenType, S>,
        token_span: std::ops::Range<usize>,
    ) -> Self {
        assert!(token.token_type() == TokenType::CharacterSet);
        Self {
            data: Some(TokenData {
                token,
                index: token_span.start,
            }),
        }
    }

    /// Visit this terminal node with the given visitor.
    pub fn visit<E, V: Visitor<'i, S, E>>(&self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_CharacterSet(self)
    }

    /// Visit this terminal node with the given visitor.
    pub fn visit_mut<E, V: VisitorMut<'i, S, E>>(&mut self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_CharacterSet(self)
    }
}

/// Hash escape sequences for characters can also be matched outside the context
/// of a string or character range.
#[derive(Clone, Debug, Default, PartialEq, Eq, Hash)]
pub struct PtCharacterLiteral<'i, S> {
    pub data: Option<TokenData<'i, S>>,
}

impl<'i, S: Default + Eq + std::hash::Hash> PtCharacterLiteral<'i, S> {
    fn new(
        token: &'i types::TerminalToken<TokenType, S>,
        token_span: std::ops::Range<usize>,
    ) -> Self {
        assert!(token.token_type() == TokenType::CharacterLiteral);
        Self {
            data: Some(TokenData {
                token,
                index: token_span.start,
            }),
        }
    }

    /// Visit this terminal node with the given visitor.
    pub fn visit<E, V: Visitor<'i, S, E>>(&self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_CharacterLiteral(self)
    }

    /// Visit this terminal node with the given visitor.
    pub fn visit_mut<E, V: VisitorMut<'i, S, E>>(&mut self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_CharacterLiteral(self)
    }
}

/// /** comments are treated as docstrings. They may only appear immediately in
/// front of a rule or toplevel alternative in a grammar production rule.
#[derive(Clone, Debug, Default, PartialEq, Eq, Hash)]
pub struct PtDoc<'i, S> {
    pub data: Option<TokenData<'i, S>>,
}

impl<'i, S: Default + Eq + std::hash::Hash> PtDoc<'i, S> {
    fn new(
        token: &'i types::TerminalToken<TokenType, S>,
        token_span: std::ops::Range<usize>,
    ) -> Self {
        assert!(token.token_type() == TokenType::Doc);
        Self {
            data: Some(TokenData {
                token,
                index: token_span.start,
            }),
        }
    }

    /// Visit this terminal node with the given visitor.
    pub fn visit<E, V: Visitor<'i, S, E>>(&self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_Doc(self)
    }

    /// Visit this terminal node with the given visitor.
    pub fn visit_mut<E, V: VisitorMut<'i, S, E>>(&mut self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_Doc(self)
    }
}

/// A grammar is a list of one or more rules.
#[derive(Clone, Debug, Default, PartialEq, Eq, Hash)]
pub struct PtGrammar<'i, S>(Vec<Box<PtRule<'i, S>>>);

impl<'i, S: Default + Eq + std::hash::Hash> PtGrammar<'i, S> {
    /// Return a Chumsky parser for this rule.
    pub fn parser(patterns: &'i TerminalPatterns<S>) -> BoxedParser<'i, PtGrammar<'i, S>, S> {
        make_parsers(patterns).0
    }

    /// Visit this nonterminal node with the given visitor.
    pub fn visit<E, V: Visitor<'i, S, E>>(&self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_Grammar(self)
    }

    /// Visit this nonterminal node with the given visitor.
    pub fn visit_mut<E, V: VisitorMut<'i, S, E>>(&mut self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_Grammar(self)
    }

    /// Visit the children of this nonterminal node with the given visitor.
    pub fn traverse<E, V: Visitor<'i, S, E>>(&self, visitor: &mut V) -> Result<(), E> {
        let x1 = &self.0;
        for x in x1.iter() {
            visitor.visit_Rule(x.as_ref())?;
        }
        Ok(())
    }

    /// Visit the children of this nonterminal node with the given visitor.
    pub fn traverse_mut<E, V: VisitorMut<'i, S, E>>(&mut self, visitor: &mut V) -> Result<(), E> {
        let x1 = &mut self.0;
        for x in x1.iter_mut() {
            visitor.visit_Rule(x.as_mut())?;
        }
        Ok(())
    }
}

/// A rule can be either a grammar or a tokenizer rule. If a rule is defined
/// more than once, each definition will just add to the alternatives.
#[derive(Clone, Debug, PartialEq, Eq, Hash)]
pub enum PtRule<'i, S> {
    /// Used to recover from errors.
    Error,

    /// A tokenizer rule, of the form `symbol :== pattern ;`. The tokenizer (if
    /// any) is expected to tokenize the input as follows:
    ///
    ///  - try matching the _ token rule and all named token rules that are
    ///    *directly* referred to from grammar production rules on the remainder
    ///    of the input;
    ///  - emit the token corresponding to the longest match to the parser, or
    ///    drop it if said longest match is the _ token;
    ///     - if there is a tie in match lengths, emit the token that was defined
    ///       earlier in the grammar (the first definition is what counts, if
    ///       there are multiple);
    ///  - if no token matched, emit an unrecognized character error and (maybe)
    ///    try to recover.
    ///
    /// Parsers that do not have a tokenizer (i.e. their tokens are simply the
    /// characters on the input) can treat these as normal rules.
    ///
    /// Tokenizer rules may not directly or indirectly refer to themselves, i.e.
    /// they may not be recursive. This allows them to be mapped onto regular
    /// expressions.
    ///
    /// Tokenizer rules that are not directly used within grammar rules are not
    /// treated as actual tokens; rather, they are treated as reusable bits of a
    /// regular expression. Borrowing ANTLR terminology, they are called
    /// fragments (but unlike in ANTLR, they are detected automatically). This is
    /// just a readability thing; it makes no difference for the matched language.
    TokenRule(
        Option<PtDoc<'i, S>>,
        PtSymbol<'i, S>,
        PtColEqEq<'i, S>,
        Box<PtAlternation<'i, S>>,
        PtSem<'i, S>,
    ),

    /// A whitespace rule, of the form `_ :== pattern ;`. Works like a normal
    /// tokenizer rule, but the token is not emitted to the parser. Parsers that
    /// do not have a tokenizer (i.e. their tokens are simply the characters on
    /// the input) must implicitly match _* at the start of the grammar and after
    /// every symbol in grammar production rules (i.e. `::=` rules).
    WhitespaceRule(
        Option<PtDoc<'i, S>>,
        PtUsc<'i, S>,
        PtColEqEq<'i, S>,
        Box<PtAlternation<'i, S>>,
        PtSem<'i, S>,
    ),

    /// A grammar production rule, for the form `symbol ::= pattern ;`. The syntax
    /// here is a bit convoluted because the toplevel alternations can be given
    /// docstrings and can be named, but the syntax is otherwise the same as for
    /// token rules.
    ///
    /// Whenever literal patterns are used in a grammar rule, they are implicitly
    /// converted to a token rule. Be mindful of this when writing the grammar:
    /// they can cause tokenizer conflicts just like any other token!
    GrammarRule(
        Option<PtDoc<'i, S>>,
        PtSymbol<'i, S>,
        Box<PtFirstAlter<'i, S>>,
        Vec<Box<PtSubseqAlter<'i, S>>>,
        PtSem<'i, S>,
    ),
}

impl<'i, S> Default for PtRule<'i, S> {
    fn default() -> Self {
        PtRule::Error
    }
}

impl<'i, S: Default + Eq + std::hash::Hash> PtRule<'i, S> {
    /// Return a Chumsky parser for this rule.
    pub fn parser(patterns: &'i TerminalPatterns<S>) -> BoxedParser<'i, PtRule<'i, S>, S> {
        make_parsers(patterns).1
    }

    /// Visit this nonterminal node with the given visitor.
    pub fn visit<E, V: Visitor<'i, S, E>>(&self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_Rule(self)
    }

    /// Visit this nonterminal node with the given visitor.
    pub fn visit_mut<E, V: VisitorMut<'i, S, E>>(&mut self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_Rule(self)
    }

    /// Visit the children of this nonterminal node with the given visitor.
    pub fn traverse<E, V: Visitor<'i, S, E>>(&self, visitor: &mut V) -> Result<(), E> {
        match self {
            PtRule::Error => (),
            PtRule::TokenRule(x1, x2, x3, x4, x5) => {
                if let Some(x) = x1.as_ref() {
                    visitor.visit_Doc(x)?;
                }
                visitor.visit_Symbol(x2)?;
                visitor.visit_ColEqEq(x3)?;
                visitor.visit_Alternation(x4.as_ref())?;
                visitor.visit_Sem(x5)?;
            }
            PtRule::WhitespaceRule(x1, x2, x3, x4, x5) => {
                if let Some(x) = x1.as_ref() {
                    visitor.visit_Doc(x)?;
                }
                visitor.visit_Usc(x2)?;
                visitor.visit_ColEqEq(x3)?;
                visitor.visit_Alternation(x4.as_ref())?;
                visitor.visit_Sem(x5)?;
            }
            PtRule::GrammarRule(x1, x2, x3, x4, x5) => {
                if let Some(x) = x1.as_ref() {
                    visitor.visit_Doc(x)?;
                }
                visitor.visit_Symbol(x2)?;
                visitor.visit_FirstAlter(x3.as_ref())?;
                for x in x4.iter() {
                    visitor.visit_SubseqAlter(x.as_ref())?;
                }
                visitor.visit_Sem(x5)?;
            }
        }
        Ok(())
    }

    /// Visit the children of this nonterminal node with the given visitor.
    pub fn traverse_mut<E, V: VisitorMut<'i, S, E>>(&mut self, visitor: &mut V) -> Result<(), E> {
        match self {
            PtRule::Error => (),
            PtRule::TokenRule(x1, x2, x3, x4, x5) => {
                if let Some(x) = x1.as_mut() {
                    visitor.visit_Doc(x)?;
                }
                visitor.visit_Symbol(x2)?;
                visitor.visit_ColEqEq(x3)?;
                visitor.visit_Alternation(x4.as_mut())?;
                visitor.visit_Sem(x5)?;
            }
            PtRule::WhitespaceRule(x1, x2, x3, x4, x5) => {
                if let Some(x) = x1.as_mut() {
                    visitor.visit_Doc(x)?;
                }
                visitor.visit_Usc(x2)?;
                visitor.visit_ColEqEq(x3)?;
                visitor.visit_Alternation(x4.as_mut())?;
                visitor.visit_Sem(x5)?;
            }
            PtRule::GrammarRule(x1, x2, x3, x4, x5) => {
                if let Some(x) = x1.as_mut() {
                    visitor.visit_Doc(x)?;
                }
                visitor.visit_Symbol(x2)?;
                visitor.visit_FirstAlter(x3.as_mut())?;
                for x in x4.iter_mut() {
                    visitor.visit_SubseqAlter(x.as_mut())?;
                }
                visitor.visit_Sem(x5)?;
            }
        }
        Ok(())
    }
}

/// `a | b | ...` preferentially matches `a`, matches `b` if `a` does not
/// match, and so on.
#[derive(Clone, Debug, Default, PartialEq, Eq, Hash)]
pub struct PtAlternation<'i, S>(
    Box<PtConcatenation<'i, S>>,
    Vec<(PtBar<'i, S>, Box<PtConcatenation<'i, S>>)>,
);

impl<'i, S: Default + Eq + std::hash::Hash> PtAlternation<'i, S> {
    /// Return a Chumsky parser for this rule.
    pub fn parser(patterns: &'i TerminalPatterns<S>) -> BoxedParser<'i, PtAlternation<'i, S>, S> {
        make_parsers(patterns).2
    }

    /// Visit this nonterminal node with the given visitor.
    pub fn visit<E, V: Visitor<'i, S, E>>(&self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_Alternation(self)
    }

    /// Visit this nonterminal node with the given visitor.
    pub fn visit_mut<E, V: VisitorMut<'i, S, E>>(&mut self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_Alternation(self)
    }

    /// Visit the children of this nonterminal node with the given visitor.
    pub fn traverse<E, V: Visitor<'i, S, E>>(&self, visitor: &mut V) -> Result<(), E> {
        let x1 = &self.0;
        let x2 = &self.1;
        visitor.visit_Concatenation(x1.as_ref())?;
        for (x1, x2) in x2.iter() {
            visitor.visit_Bar(x1)?;
            visitor.visit_Concatenation(x2.as_ref())?;
        }
        Ok(())
    }

    /// Visit the children of this nonterminal node with the given visitor.
    pub fn traverse_mut<E, V: VisitorMut<'i, S, E>>(&mut self, visitor: &mut V) -> Result<(), E> {
        let x1 = &mut self.0;
        let x2 = &mut self.1;
        visitor.visit_Concatenation(x1.as_mut())?;
        for (x1, x2) in x2.iter_mut() {
            visitor.visit_Bar(x1)?;
            visitor.visit_Concatenation(x2.as_mut())?;
        }
        Ok(())
    }
}

/// The alternatives at the root of a grammar production rule can be annotated
/// with a variant name (if not specified it is auto-generated when needed) at
/// the end and can be given a docstring before the ::= or | that starts the
/// variant. They are functionally indistinguishable from a normal, nested
/// alternation, though the parse tree may be generated in a different way.
#[derive(Clone, Debug, Default, PartialEq, Eq, Hash)]
pub struct PtFirstAlter<'i, S>(
    Option<PtDoc<'i, S>>,
    PtColColEq<'i, S>,
    Box<PtConcatenation<'i, S>>,
    Option<Box<PtAlterName<'i, S>>>,
);

impl<'i, S: Default + Eq + std::hash::Hash> PtFirstAlter<'i, S> {
    /// Return a Chumsky parser for this rule.
    pub fn parser(patterns: &'i TerminalPatterns<S>) -> BoxedParser<'i, PtFirstAlter<'i, S>, S> {
        make_parsers(patterns).3
    }

    /// Visit this nonterminal node with the given visitor.
    pub fn visit<E, V: Visitor<'i, S, E>>(&self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_FirstAlter(self)
    }

    /// Visit this nonterminal node with the given visitor.
    pub fn visit_mut<E, V: VisitorMut<'i, S, E>>(&mut self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_FirstAlter(self)
    }

    /// Visit the children of this nonterminal node with the given visitor.
    pub fn traverse<E, V: Visitor<'i, S, E>>(&self, visitor: &mut V) -> Result<(), E> {
        let x1 = &self.0;
        let x2 = &self.1;
        let x3 = &self.2;
        let x4 = &self.3;
        if let Some(x) = x1.as_ref() {
            visitor.visit_Doc(x)?;
        }
        visitor.visit_ColColEq(x2)?;
        visitor.visit_Concatenation(x3.as_ref())?;
        if let Some(x) = x4.as_ref() {
            visitor.visit_AlterName(x.as_ref())?;
        }
        Ok(())
    }

    /// Visit the children of this nonterminal node with the given visitor.
    pub fn traverse_mut<E, V: VisitorMut<'i, S, E>>(&mut self, visitor: &mut V) -> Result<(), E> {
        let x1 = &mut self.0;
        let x2 = &mut self.1;
        let x3 = &mut self.2;
        let x4 = &mut self.3;
        if let Some(x) = x1.as_mut() {
            visitor.visit_Doc(x)?;
        }
        visitor.visit_ColColEq(x2)?;
        visitor.visit_Concatenation(x3.as_mut())?;
        if let Some(x) = x4.as_mut() {
            visitor.visit_AlterName(x.as_mut())?;
        }
        Ok(())
    }
}

#[derive(Clone, Debug, Default, PartialEq, Eq, Hash)]
pub struct PtSubseqAlter<'i, S>(
    Option<PtDoc<'i, S>>,
    PtBar<'i, S>,
    Box<PtConcatenation<'i, S>>,
    Option<Box<PtAlterName<'i, S>>>,
);

impl<'i, S: Default + Eq + std::hash::Hash> PtSubseqAlter<'i, S> {
    /// Return a Chumsky parser for this rule.
    pub fn parser(patterns: &'i TerminalPatterns<S>) -> BoxedParser<'i, PtSubseqAlter<'i, S>, S> {
        make_parsers(patterns).4
    }

    /// Visit this nonterminal node with the given visitor.
    pub fn visit<E, V: Visitor<'i, S, E>>(&self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_SubseqAlter(self)
    }

    /// Visit this nonterminal node with the given visitor.
    pub fn visit_mut<E, V: VisitorMut<'i, S, E>>(&mut self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_SubseqAlter(self)
    }

    /// Visit the children of this nonterminal node with the given visitor.
    pub fn traverse<E, V: Visitor<'i, S, E>>(&self, visitor: &mut V) -> Result<(), E> {
        let x1 = &self.0;
        let x2 = &self.1;
        let x3 = &self.2;
        let x4 = &self.3;
        if let Some(x) = x1.as_ref() {
            visitor.visit_Doc(x)?;
        }
        visitor.visit_Bar(x2)?;
        visitor.visit_Concatenation(x3.as_ref())?;
        if let Some(x) = x4.as_ref() {
            visitor.visit_AlterName(x.as_ref())?;
        }
        Ok(())
    }

    /// Visit the children of this nonterminal node with the given visitor.
    pub fn traverse_mut<E, V: VisitorMut<'i, S, E>>(&mut self, visitor: &mut V) -> Result<(), E> {
        let x1 = &mut self.0;
        let x2 = &mut self.1;
        let x3 = &mut self.2;
        let x4 = &mut self.3;
        if let Some(x) = x1.as_mut() {
            visitor.visit_Doc(x)?;
        }
        visitor.visit_Bar(x2)?;
        visitor.visit_Concatenation(x3.as_mut())?;
        if let Some(x) = x4.as_mut() {
            visitor.visit_AlterName(x.as_mut())?;
        }
        Ok(())
    }
}

/// A toplevel alternative can be named by appending `-> name`. The names do not
/// have semantical meaning (they cannot be referred to within the grammar),
/// but are used to attach names to variants in the generated ASTs.
#[derive(Clone, Debug, Default, PartialEq, Eq, Hash)]
pub struct PtAlterName<'i, S>(PtMinGt<'i, S>, PtSymbol<'i, S>);

impl<'i, S: Default + Eq + std::hash::Hash> PtAlterName<'i, S> {
    /// Return a Chumsky parser for this rule.
    pub fn parser(patterns: &'i TerminalPatterns<S>) -> BoxedParser<'i, PtAlterName<'i, S>, S> {
        make_parsers(patterns).5
    }

    /// Visit this nonterminal node with the given visitor.
    pub fn visit<E, V: Visitor<'i, S, E>>(&self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_AlterName(self)
    }

    /// Visit this nonterminal node with the given visitor.
    pub fn visit_mut<E, V: VisitorMut<'i, S, E>>(&mut self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_AlterName(self)
    }

    /// Visit the children of this nonterminal node with the given visitor.
    pub fn traverse<E, V: Visitor<'i, S, E>>(&self, visitor: &mut V) -> Result<(), E> {
        let x1 = &self.0;
        let x2 = &self.1;
        visitor.visit_MinGt(x1)?;
        visitor.visit_Symbol(x2)?;
        Ok(())
    }

    /// Visit the children of this nonterminal node with the given visitor.
    pub fn traverse_mut<E, V: VisitorMut<'i, S, E>>(&mut self, visitor: &mut V) -> Result<(), E> {
        let x1 = &mut self.0;
        let x2 = &mut self.1;
        visitor.visit_MinGt(x1)?;
        visitor.visit_Symbol(x2)?;
        Ok(())
    }
}

/// `a b ...` matches `a` followed by `b` and so on.
#[derive(Clone, Debug, Default, PartialEq, Eq, Hash)]
pub struct PtConcatenation<'i, S>(Vec<Box<PtRepetition<'i, S>>>);

impl<'i, S: Default + Eq + std::hash::Hash> PtConcatenation<'i, S> {
    /// Return a Chumsky parser for this rule.
    pub fn parser(patterns: &'i TerminalPatterns<S>) -> BoxedParser<'i, PtConcatenation<'i, S>, S> {
        make_parsers(patterns).6
    }

    /// Visit this nonterminal node with the given visitor.
    pub fn visit<E, V: Visitor<'i, S, E>>(&self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_Concatenation(self)
    }

    /// Visit this nonterminal node with the given visitor.
    pub fn visit_mut<E, V: VisitorMut<'i, S, E>>(&mut self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_Concatenation(self)
    }

    /// Visit the children of this nonterminal node with the given visitor.
    pub fn traverse<E, V: Visitor<'i, S, E>>(&self, visitor: &mut V) -> Result<(), E> {
        let x1 = &self.0;
        for x in x1.iter() {
            visitor.visit_Repetition(x.as_ref())?;
        }
        Ok(())
    }

    /// Visit the children of this nonterminal node with the given visitor.
    pub fn traverse_mut<E, V: VisitorMut<'i, S, E>>(&mut self, visitor: &mut V) -> Result<(), E> {
        let x1 = &mut self.0;
        for x in x1.iter_mut() {
            visitor.visit_Repetition(x.as_mut())?;
        }
        Ok(())
    }
}

/// The usual ?*+ characters can be used to specify repetition.
#[derive(Clone, Debug, PartialEq, Eq, Hash)]
pub enum PtRepetition<'i, S> {
    /// Used to recover from errors.
    Error,

    /// `a?` greedily matches `a` zero times or once.
    Maybe(Box<PtSingular<'i, S>>, PtQst<'i, S>),

    /// `a*` greedily matches `a` zero or more times.
    Any(Box<PtSingular<'i, S>>, PtAst<'i, S>),

    /// `a+` greedily matches `a` one or more times.
    Many(Box<PtSingular<'i, S>>, PtPls<'i, S>),

    /// `a` matches `a` exactly once. Note that this one must come last in the
    /// list of alternatives, because otherwise the other alternatives would
    /// never match (because alternatives pick the *first* match, not the longest
    /// one).
    One(Box<PtSingular<'i, S>>),
}

impl<'i, S> Default for PtRepetition<'i, S> {
    fn default() -> Self {
        PtRepetition::Error
    }
}

impl<'i, S: Default + Eq + std::hash::Hash> PtRepetition<'i, S> {
    /// Return a Chumsky parser for this rule.
    pub fn parser(patterns: &'i TerminalPatterns<S>) -> BoxedParser<'i, PtRepetition<'i, S>, S> {
        make_parsers(patterns).7
    }

    /// Visit this nonterminal node with the given visitor.
    pub fn visit<E, V: Visitor<'i, S, E>>(&self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_Repetition(self)
    }

    /// Visit this nonterminal node with the given visitor.
    pub fn visit_mut<E, V: VisitorMut<'i, S, E>>(&mut self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_Repetition(self)
    }

    /// Visit the children of this nonterminal node with the given visitor.
    pub fn traverse<E, V: Visitor<'i, S, E>>(&self, visitor: &mut V) -> Result<(), E> {
        match self {
            PtRepetition::Error => (),
            PtRepetition::Maybe(x1, x2) => {
                visitor.visit_Singular(x1.as_ref())?;
                visitor.visit_Qst(x2)?;
            }
            PtRepetition::Any(x1, x2) => {
                visitor.visit_Singular(x1.as_ref())?;
                visitor.visit_Ast(x2)?;
            }
            PtRepetition::Many(x1, x2) => {
                visitor.visit_Singular(x1.as_ref())?;
                visitor.visit_Pls(x2)?;
            }
            PtRepetition::One(x1) => {
                visitor.visit_Singular(x1.as_ref())?;
            }
        }
        Ok(())
    }

    /// Visit the children of this nonterminal node with the given visitor.
    pub fn traverse_mut<E, V: VisitorMut<'i, S, E>>(&mut self, visitor: &mut V) -> Result<(), E> {
        match self {
            PtRepetition::Error => (),
            PtRepetition::Maybe(x1, x2) => {
                visitor.visit_Singular(x1.as_mut())?;
                visitor.visit_Qst(x2)?;
            }
            PtRepetition::Any(x1, x2) => {
                visitor.visit_Singular(x1.as_mut())?;
                visitor.visit_Ast(x2)?;
            }
            PtRepetition::Many(x1, x2) => {
                visitor.visit_Singular(x1.as_mut())?;
                visitor.visit_Pls(x2)?;
            }
            PtRepetition::One(x1) => {
                visitor.visit_Singular(x1.as_mut())?;
            }
        }
        Ok(())
    }
}

/// A single literal pattern or referenced rule to match, or a parenthesized
/// expression.
#[derive(Clone, Debug, PartialEq, Eq, Hash)]
pub enum PtSingular<'i, S> {
    /// Used to recover from errors.
    Error,

    Nested(PtLp<'i, S>, Box<PtAlternation<'i, S>>, PtRp<'i, S>),

    Symbol(PtSymbol<'i, S>),

    StringLiteral(PtStringLiteral<'i, S>),

    CharacterSet(PtCharacterSet<'i, S>),

    CharacterLiteral(PtCharacterLiteral<'i, S>),
}

impl<'i, S> Default for PtSingular<'i, S> {
    fn default() -> Self {
        PtSingular::Error
    }
}

impl<'i, S: Default + Eq + std::hash::Hash> PtSingular<'i, S> {
    /// Return a Chumsky parser for this rule.
    pub fn parser(patterns: &'i TerminalPatterns<S>) -> BoxedParser<'i, PtSingular<'i, S>, S> {
        make_parsers(patterns).8
    }

    /// Visit this nonterminal node with the given visitor.
    pub fn visit<E, V: Visitor<'i, S, E>>(&self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_Singular(self)
    }

    /// Visit this nonterminal node with the given visitor.
    pub fn visit_mut<E, V: VisitorMut<'i, S, E>>(&mut self, visitor: &mut V) -> Result<(), E> {
        visitor.visit_Singular(self)
    }

    /// Visit the children of this nonterminal node with the given visitor.
    pub fn traverse<E, V: Visitor<'i, S, E>>(&self, visitor: &mut V) -> Result<(), E> {
        match self {
            PtSingular::Error => (),
            PtSingular::Nested(x1, x2, x3) => {
                visitor.visit_Lp(x1)?;
                visitor.visit_Alternation(x2.as_ref())?;
                visitor.visit_Rp(x3)?;
            }
            PtSingular::Symbol(x1) => {
                visitor.visit_Symbol(x1)?;
            }
            PtSingular::StringLiteral(x1) => {
                visitor.visit_StringLiteral(x1)?;
            }
            PtSingular::CharacterSet(x1) => {
                visitor.visit_CharacterSet(x1)?;
            }
            PtSingular::CharacterLiteral(x1) => {
                visitor.visit_CharacterLiteral(x1)?;
            }
        }
        Ok(())
    }

    /// Visit the children of this nonterminal node with the given visitor.
    pub fn traverse_mut<E, V: VisitorMut<'i, S, E>>(&mut self, visitor: &mut V) -> Result<(), E> {
        match self {
            PtSingular::Error => (),
            PtSingular::Nested(x1, x2, x3) => {
                visitor.visit_Lp(x1)?;
                visitor.visit_Alternation(x2.as_mut())?;
                visitor.visit_Rp(x3)?;
            }
            PtSingular::Symbol(x1) => {
                visitor.visit_Symbol(x1)?;
            }
            PtSingular::StringLiteral(x1) => {
                visitor.visit_StringLiteral(x1)?;
            }
            PtSingular::CharacterSet(x1) => {
                visitor.visit_CharacterSet(x1)?;
            }
            PtSingular::CharacterLiteral(x1) => {
                visitor.visit_CharacterLiteral(x1)?;
            }
        }
        Ok(())
    }
}

/// Constructs Chumsky parsers for all the grammar rules.
fn make_parsers<S: Default + Eq + std::hash::Hash>(
    patterns: &TerminalPatterns<S>,
) -> (
    BoxedParser<PtGrammar<S>, S>,
    BoxedParser<PtRule<S>, S>,
    BoxedParser<PtAlternation<S>, S>,
    BoxedParser<PtFirstAlter<S>, S>,
    BoxedParser<PtSubseqAlter<S>, S>,
    BoxedParser<PtAlterName<S>, S>,
    BoxedParser<PtConcatenation<S>, S>,
    BoxedParser<PtRepetition<S>, S>,
    BoxedParser<PtSingular<S>, S>,
) {
    let mut parse_Grammar = Recursive::declare();
    let mut parse_Rule = Recursive::declare();
    let mut parse_Alternation = Recursive::declare();
    let mut parse_FirstAlter = Recursive::declare();
    let mut parse_SubseqAlter = Recursive::declare();
    let mut parse_AlterName = Recursive::declare();
    let mut parse_Concatenation = Recursive::declare();
    let mut parse_Repetition = Recursive::declare();
    let mut parse_Singular = Recursive::declare();

    parse_Grammar.define(
        parse_Rule
            .clone()
            .map(Box::new)
            .repeated()
            .at_least(1)
            .boxed()
            .map(|x| PtGrammar(x))
            .boxed(),
    );

    parse_Rule.define(
        one_of(&patterns.Doc)
            .map_with_span(PtDoc::new)
            .boxed()
            .map(Some)
            .or(empty().map(|_| None))
            .boxed()
            .then(
                one_of(&patterns.Symbol)
                    .map_with_span(PtSymbol::new)
                    .boxed(),
            )
            .then(
                one_of(&patterns.ColEqEq)
                    .map_with_span(PtColEqEq::new)
                    .boxed(),
            )
            .then(parse_Alternation.clone().map(Box::new))
            .then(one_of(&patterns.Sem).map_with_span(PtSem::new).boxed())
            .map(|((((x1, x2), x3), x4), x5)| (x1, x2, x3, x4, x5))
            .boxed()
            .map(|(x1, x2, x3, x4, x5)| PtRule::TokenRule(x1, x2, x3, x4, x5))
            .or(one_of(&patterns.Doc)
                .map_with_span(PtDoc::new)
                .boxed()
                .map(Some)
                .or(empty().map(|_| None))
                .boxed()
                .then(one_of(&patterns.Usc).map_with_span(PtUsc::new).boxed())
                .then(
                    one_of(&patterns.ColEqEq)
                        .map_with_span(PtColEqEq::new)
                        .boxed(),
                )
                .then(parse_Alternation.clone().map(Box::new))
                .then(one_of(&patterns.Sem).map_with_span(PtSem::new).boxed())
                .map(|((((x1, x2), x3), x4), x5)| (x1, x2, x3, x4, x5))
                .boxed()
                .map(|(x1, x2, x3, x4, x5)| PtRule::WhitespaceRule(x1, x2, x3, x4, x5)))
            .or(one_of(&patterns.Doc)
                .map_with_span(PtDoc::new)
                .boxed()
                .map(Some)
                .or(empty().map(|_| None))
                .boxed()
                .then(
                    one_of(&patterns.Symbol)
                        .map_with_span(PtSymbol::new)
                        .boxed(),
                )
                .then(parse_FirstAlter.clone().map(Box::new))
                .then(parse_SubseqAlter.clone().map(Box::new).repeated().boxed())
                .then(one_of(&patterns.Sem).map_with_span(PtSem::new).boxed())
                .map(|((((x1, x2), x3), x4), x5)| (x1, x2, x3, x4, x5))
                .boxed()
                .map(|(x1, x2, x3, x4, x5)| PtRule::GrammarRule(x1, x2, x3, x4, x5)))
            .boxed(),
    );

    parse_Alternation.define(
        parse_Concatenation
            .clone()
            .map(Box::new)
            .then(
                one_of(&patterns.Bar)
                    .map_with_span(PtBar::new)
                    .boxed()
                    .then(parse_Concatenation.clone().map(Box::new))
                    .map(|(x1, x2)| (x1, x2))
                    .boxed()
                    .repeated()
                    .boxed(),
            )
            .map(|(x1, x2)| (x1, x2))
            .boxed()
            .map(|(x1, x2)| PtAlternation(x1, x2))
            .boxed(),
    );

    parse_FirstAlter.define(
        one_of(&patterns.Doc)
            .map_with_span(PtDoc::new)
            .boxed()
            .map(Some)
            .or(empty().map(|_| None))
            .boxed()
            .then(
                one_of(&patterns.ColColEq)
                    .map_with_span(PtColColEq::new)
                    .boxed(),
            )
            .then(parse_Concatenation.clone().map(Box::new))
            .then(
                parse_AlterName
                    .clone()
                    .map(Box::new)
                    .map(Some)
                    .or(empty().map(|_| None))
                    .boxed(),
            )
            .map(|(((x1, x2), x3), x4)| (x1, x2, x3, x4))
            .boxed()
            .map(|(x1, x2, x3, x4)| PtFirstAlter(x1, x2, x3, x4))
            .boxed(),
    );

    parse_SubseqAlter.define(
        one_of(&patterns.Doc)
            .map_with_span(PtDoc::new)
            .boxed()
            .map(Some)
            .or(empty().map(|_| None))
            .boxed()
            .then(one_of(&patterns.Bar).map_with_span(PtBar::new).boxed())
            .then(parse_Concatenation.clone().map(Box::new))
            .then(
                parse_AlterName
                    .clone()
                    .map(Box::new)
                    .map(Some)
                    .or(empty().map(|_| None))
                    .boxed(),
            )
            .map(|(((x1, x2), x3), x4)| (x1, x2, x3, x4))
            .boxed()
            .map(|(x1, x2, x3, x4)| PtSubseqAlter(x1, x2, x3, x4))
            .boxed(),
    );

    parse_AlterName.define(
        one_of(&patterns.MinGt)
            .map_with_span(PtMinGt::new)
            .boxed()
            .then(
                one_of(&patterns.Symbol)
                    .map_with_span(PtSymbol::new)
                    .boxed(),
            )
            .map(|(x1, x2)| (x1, x2))
            .boxed()
            .map(|(x1, x2)| PtAlterName(x1, x2))
            .boxed(),
    );

    parse_Concatenation.define(
        parse_Repetition
            .clone()
            .map(Box::new)
            .repeated()
            .at_least(1)
            .boxed()
            .map(|x| PtConcatenation(x))
            .boxed(),
    );

    parse_Repetition.define(
        parse_Singular
            .clone()
            .map(Box::new)
            .then(one_of(&patterns.Qst).map_with_span(PtQst::new).boxed())
            .map(|(x1, x2)| (x1, x2))
            .boxed()
            .map(|(x1, x2)| PtRepetition::Maybe(x1, x2))
            .or(parse_Singular
                .clone()
                .map(Box::new)
                .then(one_of(&patterns.Ast).map_with_span(PtAst::new).boxed())
                .map(|(x1, x2)| (x1, x2))
                .boxed()
                .map(|(x1, x2)| PtRepetition::Any(x1, x2)))
            .or(parse_Singular
                .clone()
                .map(Box::new)
                .then(one_of(&patterns.Pls).map_with_span(PtPls::new).boxed())
                .map(|(x1, x2)| (x1, x2))
                .boxed()
                .map(|(x1, x2)| PtRepetition::Many(x1, x2)))
            .or(parse_Singular
                .clone()
                .map(Box::new)
                .map(|x| PtRepetition::One(x)))
            .boxed(),
    );

    parse_Singular.define(
        one_of(&patterns.Lp)
            .map_with_span(PtLp::new)
            .boxed()
            .then(parse_Alternation.clone().map(Box::new))
            .then(one_of(&patterns.Rp).map_with_span(PtRp::new).boxed())
            .map(|((x1, x2), x3)| (x1, x2, x3))
            .boxed()
            .map(|(x1, x2, x3)| PtSingular::Nested(x1, x2, x3))
            .or(one_of(&patterns.Symbol)
                .map_with_span(PtSymbol::new)
                .boxed()
                .map(|x| PtSingular::Symbol(x)))
            .or(one_of(&patterns.StringLiteral)
                .map_with_span(PtStringLiteral::new)
                .boxed()
                .map(|x| PtSingular::StringLiteral(x)))
            .or(one_of(&patterns.CharacterSet)
                .map_with_span(PtCharacterSet::new)
                .boxed()
                .map(|x| PtSingular::CharacterSet(x)))
            .or(one_of(&patterns.CharacterLiteral)
                .map_with_span(PtCharacterLiteral::new)
                .boxed()
                .map(|x| PtSingular::CharacterLiteral(x)))
            .boxed(),
    );

    (
        parse_Grammar.then_ignore(end()).boxed(),
        parse_Rule.then_ignore(end()).boxed(),
        parse_Alternation.then_ignore(end()).boxed(),
        parse_FirstAlter.then_ignore(end()).boxed(),
        parse_SubseqAlter.then_ignore(end()).boxed(),
        parse_AlterName.then_ignore(end()).boxed(),
        parse_Concatenation.then_ignore(end()).boxed(),
        parse_Repetition.then_ignore(end()).boxed(),
        parse_Singular.then_ignore(end()).boxed(),
    )
}

/// Visitor trait for immutably walking the parse tree.
pub trait Visitor<'i, S, E = ()>
where
    Self: Sized,
    S: Default + Eq + std::hash::Hash,
{
    fn visit_ColEqEq(&mut self, _x: &PtColEqEq<'i, S>) -> Result<(), E> {
        Ok(())
    }

    fn visit_Sem(&mut self, _x: &PtSem<'i, S>) -> Result<(), E> {
        Ok(())
    }

    fn visit_Usc(&mut self, _x: &PtUsc<'i, S>) -> Result<(), E> {
        Ok(())
    }

    fn visit_Symbol(&mut self, _x: &PtSymbol<'i, S>) -> Result<(), E> {
        Ok(())
    }

    fn visit_Bar(&mut self, _x: &PtBar<'i, S>) -> Result<(), E> {
        Ok(())
    }

    fn visit_ColColEq(&mut self, _x: &PtColColEq<'i, S>) -> Result<(), E> {
        Ok(())
    }

    fn visit_MinGt(&mut self, _x: &PtMinGt<'i, S>) -> Result<(), E> {
        Ok(())
    }

    fn visit_Qst(&mut self, _x: &PtQst<'i, S>) -> Result<(), E> {
        Ok(())
    }

    fn visit_Ast(&mut self, _x: &PtAst<'i, S>) -> Result<(), E> {
        Ok(())
    }

    fn visit_Pls(&mut self, _x: &PtPls<'i, S>) -> Result<(), E> {
        Ok(())
    }

    fn visit_Lp(&mut self, _x: &PtLp<'i, S>) -> Result<(), E> {
        Ok(())
    }

    fn visit_Rp(&mut self, _x: &PtRp<'i, S>) -> Result<(), E> {
        Ok(())
    }

    fn visit_StringLiteral(&mut self, _x: &PtStringLiteral<'i, S>) -> Result<(), E> {
        Ok(())
    }

    fn visit_CharacterSet(&mut self, _x: &PtCharacterSet<'i, S>) -> Result<(), E> {
        Ok(())
    }

    fn visit_CharacterLiteral(&mut self, _x: &PtCharacterLiteral<'i, S>) -> Result<(), E> {
        Ok(())
    }

    fn visit_Doc(&mut self, _x: &PtDoc<'i, S>) -> Result<(), E> {
        Ok(())
    }

    fn visit_Grammar(&mut self, x: &PtGrammar<'i, S>) -> Result<(), E> {
        x.traverse(self)
    }

    fn visit_Rule(&mut self, x: &PtRule<'i, S>) -> Result<(), E> {
        x.traverse(self)
    }

    fn visit_Alternation(&mut self, x: &PtAlternation<'i, S>) -> Result<(), E> {
        x.traverse(self)
    }

    fn visit_FirstAlter(&mut self, x: &PtFirstAlter<'i, S>) -> Result<(), E> {
        x.traverse(self)
    }

    fn visit_SubseqAlter(&mut self, x: &PtSubseqAlter<'i, S>) -> Result<(), E> {
        x.traverse(self)
    }

    fn visit_AlterName(&mut self, x: &PtAlterName<'i, S>) -> Result<(), E> {
        x.traverse(self)
    }

    fn visit_Concatenation(&mut self, x: &PtConcatenation<'i, S>) -> Result<(), E> {
        x.traverse(self)
    }

    fn visit_Repetition(&mut self, x: &PtRepetition<'i, S>) -> Result<(), E> {
        x.traverse(self)
    }

    fn visit_Singular(&mut self, x: &PtSingular<'i, S>) -> Result<(), E> {
        x.traverse(self)
    }
}

/// Visitor trait for mutably walking the parse tree.
pub trait VisitorMut<'i, S, E = ()>
where
    Self: Sized,
    S: Default + Eq + std::hash::Hash,
{
    fn visit_ColEqEq(&mut self, _x: &mut PtColEqEq<'i, S>) -> Result<(), E> {
        Ok(())
    }

    fn visit_Sem(&mut self, _x: &mut PtSem<'i, S>) -> Result<(), E> {
        Ok(())
    }

    fn visit_Usc(&mut self, _x: &mut PtUsc<'i, S>) -> Result<(), E> {
        Ok(())
    }

    fn visit_Symbol(&mut self, _x: &mut PtSymbol<'i, S>) -> Result<(), E> {
        Ok(())
    }

    fn visit_Bar(&mut self, _x: &mut PtBar<'i, S>) -> Result<(), E> {
        Ok(())
    }

    fn visit_ColColEq(&mut self, _x: &mut PtColColEq<'i, S>) -> Result<(), E> {
        Ok(())
    }

    fn visit_MinGt(&mut self, _x: &mut PtMinGt<'i, S>) -> Result<(), E> {
        Ok(())
    }

    fn visit_Qst(&mut self, _x: &mut PtQst<'i, S>) -> Result<(), E> {
        Ok(())
    }

    fn visit_Ast(&mut self, _x: &mut PtAst<'i, S>) -> Result<(), E> {
        Ok(())
    }

    fn visit_Pls(&mut self, _x: &mut PtPls<'i, S>) -> Result<(), E> {
        Ok(())
    }

    fn visit_Lp(&mut self, _x: &mut PtLp<'i, S>) -> Result<(), E> {
        Ok(())
    }

    fn visit_Rp(&mut self, _x: &mut PtRp<'i, S>) -> Result<(), E> {
        Ok(())
    }

    fn visit_StringLiteral(&mut self, _x: &mut PtStringLiteral<'i, S>) -> Result<(), E> {
        Ok(())
    }

    fn visit_CharacterSet(&mut self, _x: &mut PtCharacterSet<'i, S>) -> Result<(), E> {
        Ok(())
    }

    fn visit_CharacterLiteral(&mut self, _x: &mut PtCharacterLiteral<'i, S>) -> Result<(), E> {
        Ok(())
    }

    fn visit_Doc(&mut self, _x: &mut PtDoc<'i, S>) -> Result<(), E> {
        Ok(())
    }

    fn visit_Grammar(&mut self, x: &mut PtGrammar<'i, S>) -> Result<(), E> {
        x.traverse_mut(self)
    }

    fn visit_Rule(&mut self, x: &mut PtRule<'i, S>) -> Result<(), E> {
        x.traverse_mut(self)
    }

    fn visit_Alternation(&mut self, x: &mut PtAlternation<'i, S>) -> Result<(), E> {
        x.traverse_mut(self)
    }

    fn visit_FirstAlter(&mut self, x: &mut PtFirstAlter<'i, S>) -> Result<(), E> {
        x.traverse_mut(self)
    }

    fn visit_SubseqAlter(&mut self, x: &mut PtSubseqAlter<'i, S>) -> Result<(), E> {
        x.traverse_mut(self)
    }

    fn visit_AlterName(&mut self, x: &mut PtAlterName<'i, S>) -> Result<(), E> {
        x.traverse_mut(self)
    }

    fn visit_Concatenation(&mut self, x: &mut PtConcatenation<'i, S>) -> Result<(), E> {
        x.traverse_mut(self)
    }

    fn visit_Repetition(&mut self, x: &mut PtRepetition<'i, S>) -> Result<(), E> {
        x.traverse_mut(self)
    }

    fn visit_Singular(&mut self, x: &mut PtSingular<'i, S>) -> Result<(), E> {
        x.traverse_mut(self)
    }
}

#[test]
fn test_self_spec() {
    let mut tokenizer_errors = vec![];
    let tokens: Vec<_> = tokenize(include_str!("../pangram/self-spec.ebnf"))
        .filter_map(|x| match x.into_grammar_input() {
            Ok(x) => Some(x),
            Err(x) => {
                if let Ok(error) = x.into_error() {
                    tokenizer_errors.push(error);
                }
                None
            }
        })
        .collect();
    let patterns = TerminalPatterns::default();
    let result = PtGrammar::parser(&patterns).parse_with_recovery(&tokens[..]);

    println!("{:#?}", result.tree());
    let parser_errors = result.errors().collect::<Vec<_>>();

    if !tokenizer_errors.is_empty() || !parser_errors.is_empty() {
        println!("Errors:");
        for error in tokenizer_errors.iter() {
            println!(" - {error:#?}");
        }
        for error in parser_errors.iter() {
            println!(" - {error:#?}");
        }
    }

    assert!(tokenizer_errors.is_empty());
    assert!(parser_errors.is_empty());
}

#[test]
fn test_simple() {
    let mut tokenizer_errors = vec![];
    let tokens: Vec<_> = tokenize(include_str!("../pangram/simple.ebnf"))
        .filter_map(|x| match x.into_grammar_input() {
            Ok(x) => Some(x),
            Err(x) => {
                if let Ok(error) = x.into_error() {
                    tokenizer_errors.push(error);
                }
                None
            }
        })
        .collect();
    let patterns = TerminalPatterns::default();
    let result = PtGrammar::parser(&patterns).parse_with_recovery(&tokens[..]);

    println!("{:#?}", result.tree());
    let parser_errors = result.errors().collect::<Vec<_>>();

    if !tokenizer_errors.is_empty() || !parser_errors.is_empty() {
        println!("Errors:");
        for error in tokenizer_errors.iter() {
            println!(" - {error:#?}");
        }
        for error in parser_errors.iter() {
            println!(" - {error:#?}");
        }
    }

    assert!(tokenizer_errors.is_empty());
    assert!(parser_errors.is_empty());
}
